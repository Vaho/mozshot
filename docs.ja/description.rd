= Mozshot 概要

Mozshot は単に次の要求を満たすために実験として作られました。

 * ruby で何か書きたい
 * Rinda 使ってみたい
 * ruby-gtkmozembed が本当に動くのか試してみたい
 * Xvfb をさわってみたい
 * FastCGI + ruby でどこまで行けるか試してみたい

実際に動いてる様子は ((<URL:http://mozshot.nemui.org/>)) で見ることが出来ます。

== コンポーネント

大きく分けて以下の構成で出来ています。

 * タプルスペース - プロセス間通信用
 * スクリーンショットデーモン - mozilla コンポーネントを使って HTML をレンダリングし、画像を生成
 * CGIフロントエンド - ユーザの要求に沿って画像を返す。無ければスクリーンショット要求を出す
 * 補助用スクリプト群

各コンポーネントはタプルスペースを通じて通信することによって連携しています。

コンポーネントの独立性が高いため、コンポーネント単位で再起動したり
置き換えたりすることが可能です。

TODO: 図を入れる

== 処理のながれ

=== ディスクに期限内のキャッシュがある時

TODO: 図

=== ディスクに期限切れのキャッシュがある時

TODO: 図

=== キャッシュがない時

TODO: 図

== コンポーネントの少し詳細な説明

=== タプルスペース

各プロセスが協調動作するための通信路として使われています。
咳さんによる ((<Rinda|URL:http://www2a.biglobe.ne.jp/seki/ruby/d208.html>))
を使っています。タプルスペース自体の具体的な動作は Rinda の説明を読んで下さい。

タプルスペースには以下のタプルが投入されます（詳細は各コンポーネントの説明を）。

 * スクリーンショットリクエスト
   * 対象の URL, サイズ情報などなど。
 * 取得したスクリーンショット応答
   * 対象 URL, とステータスなどを含みます。成功した場合は画像のバイナリがそのままタプルに入っています
 * 処理中マーク

タプルスペースが停止した場合、その時の未処理のリクエストや、まだ中に残っ
ている画像が失われます。また、各プロセスが通信できなくなるので実質動作
が停止します。

ただ、再起動などで入っていたタプルが失われても（そのうちまた要求があっ
て）再投入されるのでさほど問題はありません。頻繁にリクエストされるもの
はそのうち画像が作られるでしょう。（逆に言えばリクエストにはその程度の
信頼性しかありません。）

メモリ肥大や応答が無くなった時は、単純に kill で殺して再起動します。

==== リクエストタプルの構造

 * (Symbol) 固定の識別子 :req
 * (任意) リクエストID
 * (Symbol) スクリーンショットの返却方法識別子 (実際使ってるのはほぼ :shot_buf 固定)
 * (Hash) リクエストの詳細 (URLやサイズなど)

==== 応答タプルの構造

 * (Symbol) 固定の識別子 :req
 * (任意) リクエストID
 * (Symbol) 結果識別子 :success | :error
 * (Hash) 結果の情報(画像バイナリなど)

==== 処理中マーク用タプルの構造

 * (Symbol) 固定の識別子 :stat
 * (任意) 現在処理中のリクエストID
 * (Hash) 詳細 (タイムスタンプや処理中のプロセスIDなど)

CGI が現在処理中のリクエストを再投入しないようにするために使われています。

=== スクリーンショットデーモン

gtkmozembed を使って実際に画像を生成するデーモンです。
コマンドラインからも使えますが、タプルスペースからのリクエストを待つモードで
動かすと連続処理出来るようになっています。

今の書き方だと１プロセスでは並列処理できないので、画像生成を並列化する
には複数のプロセスを上げる必要がある。プロセス毎にに占有できる X のスク
リーンが必要。Xvfb に複数の -screen オプションを付けて起動し、DISPLAY
環境変数でスクリーン番号を替えて起動すると便利。

起動時に ~/.mozilla/mozshot/default のテンプレートから
~/.mozilla/mozshot/proc-((*プロセスID*)) へプロファイルをコピーして使います。

また、メインループに入る前に
~/.mozilla/mozshot/proc-((*プロセスID*))/drbsock という UNIX
ドメインソケットを作るのでこれ経由でデーモンと通信できます。
 
==== メインループ

 (1) タプルスペースに繋いでリクエストタプルを待つ
 (2) リクエストタプルを受け取ったら処理中マークのタプルを書き戻す
 (3) 実際に HTML を描画して GDK pixbuf でスクリーンショットを取る
 (4) 1に戻る

=== CGI フロントエンド

Apache と FastCGI を使った CGI フロントエンド。
ディスク上の画像キャッシュから画像を拾い、クライアントに返します。
画像が無い場合はタプルスペースにリクエストを書き込みます。

 (1) リクエストをパースしてターゲットの URL やサイズからキャッシュのユニークIDを生成
 (2) ID からキャッシュを探査する
 (3) キャッシュ内に期限内の画像が見つかったら Apache が画像を返して終わり
 (4) 無ければその ID がリクエスト済みかチェック

TODO! 書きかけ！

== 議論/問題点/課題

=== タプルスペース

==== タプルあふれ

現在の Rinda の実装ではタプルの数があまりに増えすぎると、パフォーマンスが低下する。

短時間に多数のスクリーンショット生成要求が出された場合に、この問題が顕著あらわれる。
リクエスト用のタプルが1000近くに達するとほぼ応答が帰ってこなくなることがあった。

==== メモリの肥大化

また、タプルスペースとして起動しているプロセスのメモリの使用量がだんだ
ん上がって行く。これに関してはメモリリークしているのかもしれないが、
調べていない（簡単に調べる方法は何か無いかな？）。

ただ、画像のバイナリをそのままタプルの中に入れている構造上、どうしても
メモリサイズは随分大きくなってしまう。画像のやりとりはスクリーンショッ
トサーバ側に別の通信経路を用意して、タプルにはその URI を入れるなどの処
理をした方が良かった。

==== キューの優先度がない

全てのリクエストキューが同じ優先度で扱われている。大抵の場合、期限内の
スクリーンショットを更新する場合より、新規に作成する場合を優先した方が
良いだろう。しかし、そう言う仕組みを Rinda でやろうとすると通常の take
ではちょっと面倒くさい。

((<Apache ActiveMQ|URL:http://activemq.apache.org/>))
などの特化した実装の方が向いているだろう。

=== スクリーンショットデーモン

==== Mozilla のプロファイルコピーが無駄

プロセスが上がる毎に、毎回プロファイルディレクトリをテンプレートからコピーしている。
これは頻繁にプロセスが置き換わる場合には、かなりのディスク I/O の無駄になる。
また、キャッシュがプロファイル毎に作られるため、それも共有できない。
（squid を使うとましだが、各プロファイルに無駄なキャッシュが出来てしまうのは変わらない。）

==== モーダルダイアログを閉じる手段が分からない

JavaScript などでモーダルダイアログが開いてしまうと、それを閉じる手段が分からない。
destory を呼んだら segv で死んでしまった。何か間違ってる？

==== gtkmozembed が不安定

ちゃんと調べていないのだが、しばらくスクリーンショットを取っていると何故かブロックしてしまう。
条件が特定できていない。特定のサイトで必ず起こる訳でもないようだ。

==== メモリが無駄

パラメータをチューニングしても mozilla コンポーネントがかなりメモリを食
うので、プロセスを沢山動かすにはなかなかきつい。

これは mozilla がこういう使い方を想定して作られていないためで、mozshot
の使い方が悪い。一つのプロセスで複数のウィンドウを敷き詰めるとかをした
方が良いのだろう。出来れば。

=== フロントエンドの CGI 部分

==== 独自の一次キューが必要

CGI がいちいちタプルスペースと直接通信すると、タプルスペース側で問題が
起こった時に引きずられて停止してしまう可能性が大きい。たとえ0.5秒のタイ
ムアウト待ちだったとしても、 Web サーバへのリクエストが多い場合には致命
的になる。

CGI は独自に高速で高信頼なキューを持つ様にして、そこから別のプロセスが
改めてタプルスペースにリクエストタプルを書くようにすべきだった。

==== 分散が難しい

負荷分散などを考えると、フロントの CGI は分散できるようにしたい。
しかし、ディスク上に置かれた画像のキャッシュを手軽に分散する方法があまりない。
rsync でスキャンするのは非効率。かといって NFS ではあまり意味がない。
でも分散ファイルシステムを使うのはちょっと手軽とは言い難い。

応答のタプルを期限切れまで消さずに残しておいて、複数のフロントエンドが
それぞれ全部をディスクに書くようにするというのは単純で良いけど、
おそらくタプルスペースがそれに耐えられない。

=== 総括

 * Rinda はプロセス間で協調動作が必要なシステムを手軽に作れる
   * でもタプルの設計は慎重に行おう。タプルの構造の設計は通信プロトコルの設計と同じ。
     途中で変えると面倒な事になる。
   * 汎用的に何にでも使えるけれど、何かに強いわけではない。
     パフォーマンスが必要なら特化したものを使った方が良いかも。
 * コンポーネントの独立性を上げて、別々に再起動出来るようにしておくととても便利
 * リクエストが失われても勝手に再投入される仕組みは気楽でいい
   * ただしリクエストがあまり溜まりすぎない程度に処理できる必要がある
